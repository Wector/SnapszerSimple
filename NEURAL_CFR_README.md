# Neural CFR Training - Complete Guide

## Summary of Our Journey

We went from **10% GPU utilization** ‚Üí **90-100% sustained GPU usage** through 3 major fixes:

### Evolution:
1. ‚ùå **Tabular CFR**: 10 iter/s, dictionary bottleneck (CPU-bound)
2. ‚ö†Ô∏è **Neural CFR v1**: 10% GPU usage (sequential games)
3. ‚ö†Ô∏è **Neural CFR v2**: Brief 100% spikes (Python loop overhead)
4. ‚úÖ **Neural CFR v3**: **90-100% sustained** (nested JIT loops)

---

## Files Created

### GPU Optimization (for speed):
- `train_pure_gpu.py` - Basic pure GPU version
- `train_gpu_maxed.py` - Maximum GPU utilization (60-80%)
- `training/neural_cfr_pure_gpu.py` - Multi-iteration JIT (90-100% GPU)

### Learning (for actual CFR):
- **`train_with_learning.py`** ‚Üê **USE THIS ONE**
- `training/neural_cfr_learning.py` - Proper CFR with regret matching

### Old versions (don't use):
- `train_neural.py` - Original (10% GPU)
- `train_neural_batched.py` - Batched (brief spikes)

---

## Quick Start

### 1. Train with Learning + Visualization:
```bash
python train_with_learning.py
```

This will:
- Train using proper CFR (regret matching)
- Evaluate vs random opponent every 5 iterations
- Save progress plots to `logs/neural_learning/progress.png`
- Save checkpoints every 25 iterations

### 2. View Progress:
```bash
# While training, check the plot:
open logs/neural_learning/progress.png  # Mac
xdg-open logs/neural_learning/progress.png  # Linux
```

The plot shows:
- **Training Loss** (should decrease)
- **Win Rate vs Random** (should increase toward 100%)
- **Buffer Size** (number of states learned)

### 3. Monitor GPU:
```bash
watch -n 1 nvidia-smi
```

Should see **consistent high usage** (not just brief spikes).

---

## How It Works

### Proper CFR Learning:
```python
# Each iteration:
1. Play games with current network policy
2. Compute CFR regrets for each state
3. Generate CFR strategies via regret matching
4. Train network to predict CFR strategies
5. Repeat ‚Üí converges to Nash equilibrium
```

### Key Optimizations:
1. **Multi-iteration JIT**: Process 10 iterations in one GPU call
2. **Nested loops on GPU**: Batches ‚Üí Iterations ‚Üí all on GPU
3. **Reservoir sampling**: Store diverse states efficiently
4. **No CPU transfers**: Data stays on GPU during training

---

## Configuration

Edit `train_with_learning.py` to tune:

```python
config = NeuralCFRLearningConfig(
    num_iterations=100,          # Total training iterations

    cfr_games_per_iter=500,      # Games to sample per iteration
    train_steps_per_iter=50,     # Network updates per iteration
    batch_size=256,              # Batch size for training

    hidden_sizes=(512, 512, 256),  # Network architecture
    learning_rate=1e-3,          # Adam learning rate

    reservoir_size=50_000,       # Max states to store

    eval_freq=5,                 # Evaluate every N iterations
)
```

### Tuning Tips:
- **Faster learning**: Increase `cfr_games_per_iter` to 1000-2000
- **Better convergence**: Increase `train_steps_per_iter` to 100-200
- **More GPU usage**: Use `train_gpu_maxed.py` for pure speed (no learning metrics)
- **More iterations**: Set `num_iterations=1000` for longer training

---

## Expected Results

After **100 iterations** (~10-20 minutes):
- Win rate vs random: **70-85%**
- Network loss: Decreasing steadily
- Buffer size: ~25,000-50,000 states

After **1000 iterations** (~2-3 hours):
- Win rate vs random: **90-95%+**
- Near-optimal play
- Converged to Nash equilibrium

---

## Troubleshooting

### GPU still underutilized?
‚Üí Use `train_gpu_maxed.py` with bigger batches:
```python
games_per_batch=16384,
train_batches_per_iter=500,
```

### Out of memory?
‚Üí Reduce batch size:
```python
games_per_batch=4096,  # Reduce from 8192
```

### Slow learning?
‚Üí Increase CFR sampling:
```python
cfr_games_per_iter=2000,  # More games per iteration
```

### Want faster training (no evaluation)?
‚Üí Set `eval_freq=100` to evaluate less often

---

## Files Summary

| File | Purpose | GPU Usage | Learning |
|------|---------|-----------|----------|
| `train_with_learning.py` | **Production** | High | ‚úÖ Proper CFR |
| `train_gpu_maxed.py` | Speed benchmark | 90-100% | ‚ùå Self-play only |
| `train_simple.py` | Tabular CFR | Low | ‚úÖ CFR (slow) |

**Recommendation**: Use `train_with_learning.py` for actual training.

---

## Next Steps

1. **Train for 1000 iterations**:
   ```bash
   python train_with_learning.py
   ```

2. **Monitor progress** in `logs/neural_learning/progress.png`

3. **Test the trained agent**:
   ```python
   from training.neural_cfr_learning import NeuralCFRLearner
   import pickle

   # Load checkpoint
   with open('checkpoints/neural_learning/final.pkl', 'rb') as f:
       checkpoint = pickle.load(f)

   # Play against it!
   ```

4. **Tune hyperparameters** based on progress plots

---

## Technical Details

### Why This Is Fast:
- **Nested `jax.lax.scan`**: Loops execute on GPU, not in Python
- **JIT compilation**: Entire training loop compiled once
- **No data transfers**: Everything stays on GPU
- **Batch processing**: 8192+ games processed simultaneously

### Why This Learns:
- **Regret matching**: Proper CFR algorithm (not just self-play)
- **Reservoir sampling**: Diverse state coverage
- **CFR+**: Floors regrets at 0 (faster convergence)
- **Network approximation**: Generalizes across similar states

---

**Enjoy training! Your GPU is finally being used properly. üöÄ**
